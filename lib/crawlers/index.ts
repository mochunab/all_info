// ë²”ìš© í¬ë¡¤ëŸ¬ ë©”ì¸ ëª¨ë“ˆ
// ì „ëµ íŒ¨í„´ ê¸°ë°˜ í¬ë¡¤ë§ ì‹œìŠ¤í…œ

import { SupabaseClient } from '@supabase/supabase-js';
import type { Database } from '@/types/database';
import type { CrawlSource } from '@/types';
import type { CrawlerType, CrawlResult, CrawledArticle, RawContentItem } from './types';
import { parseConfig } from './types';
import { getStrategy, inferCrawlerType, closeBrowser, isValidCrawlerType } from './strategies';
import { parseDateToISO } from './date-parser';
import { generateSourceId } from '@/lib/utils';
import { filterGarbageArticles, getQualityStats } from './quality-filter';

// Legacy imports for backward compatibility
import { crawlWithCheerio, fetchArticleContent } from './cheerio-crawler';
import { crawlWithPlaywright } from './playwright-crawler';

// Site-specific crawlers (ë ˆê±°ì‹œ)
import { crawlIconsumer } from './sites/iconsumer';
import { crawlBrunch } from './sites/brunch';
import { crawlWiseapp } from './sites/wiseapp';
import { crawlOpenads } from './sites/openads';
import { crawlRetailtalk } from './sites/retailtalk';
import { crawlStonebc } from './sites/stonebc';
import { crawlBuybrand } from './sites/buybrand';

// Legacy crawler registry
const LEGACY_CRAWLER_REGISTRY: Record<string, (source: CrawlSource) => Promise<CrawledArticle[]>> = {
  'ì•„ì´ì»¨ìŠˆë¨¸': crawlIconsumer,
  'ë¸ŒëŸ°ì¹˜-ëª¨ë¹„ì¸ì‚¬ì´ë“œ': crawlBrunch,
  'ë¸ŒëŸ°ì¹˜-ìŠ¤íƒ€íŠ¸ì—…': crawlBrunch,
  'ë¸ŒëŸ°ì¹˜-íŠ¸ë Œë“œë¯¸ë””ì—„': crawlBrunch,
  'ì™€ì´ì¦ˆì•±': crawlWiseapp,
  'ì˜¤í”ˆì• ì¦ˆ': crawlOpenads,
  'ë¦¬í…Œì¼í†¡': crawlRetailtalk,
  'ìŠ¤í†¤ë¸Œë¦¿ì§€': crawlStonebc,
  'ë°”ì´ë¸Œëœë“œ': crawlBuybrand,
};

/**
 * RawContentItemì„ CrawledArticleë¡œ ë³€í™˜
 */
function convertToArticle(
  item: RawContentItem,
  source: CrawlSource,
  category?: string
): CrawledArticle {
  return {
    source_id: generateSourceId(item.link),
    source_name: source.name,
    source_url: item.link,
    title: item.title,
    thumbnail_url: item.thumbnail || undefined,
    content_preview: item.content,
    author: item.author || undefined,
    published_at: parseDateToISO(item.dateStr),
    category: category || parseConfig(source).category,
  };
}

/**
 * í¬ë¡¤ë§ ê²°ê³¼ í’ˆì§ˆ ê²€ì¦
 */
type ValidationResult = {
  passed: boolean;
  reason?: string;
  stats?: {
    total: number;
    valid: number;
    garbageRatio: number;
    uniqueTitles: number;
    uniqueUrls: number;
  };
};

/**
 * ì†ŒìŠ¤ config ì—…ë°ì´íŠ¸ (ìë™ ë³µêµ¬ìš©)
 */
async function updateSourceConfig(
  sourceId: number,
  newConfig: {
    crawlerType: CrawlerType;
    selectors?: Record<string, unknown>;
    rssUrl?: string;
    confidence?: number;
    detectionMethod?: string;
  }
): Promise<void> {
  try {
    const { createServiceClient } = await import('@/lib/supabase/server');
    const supabase = createServiceClient();

    const updates: {
      crawler_type: string;
      config?: Record<string, unknown>;
      crawl_url?: string;
    } = {
      crawler_type: newConfig.crawlerType,
    };

    // config ë³‘í•© (ê¸°ì¡´ ì„¤ì • ìœ ì§€í•˜ë©´ì„œ ìƒˆ ì„¤ì • ì¶”ê°€)
    if (newConfig.selectors || newConfig.confidence || newConfig.detectionMethod) {
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const { data: currentSource } = await (supabase as any)
        .from('crawl_sources')
        .select('config')
        .eq('id', sourceId)
        .single();

      const currentConfig = currentSource?.config || {};

      updates.config = {
        ...currentConfig,
        ...(newConfig.selectors && { selectors: newConfig.selectors }),
        _detection: {
          method: newConfig.detectionMethod || 'auto-recovery',
          confidence: newConfig.confidence || 0.5,
          timestamp: new Date().toISOString(),
          reason: 'Auto-recovery after quality validation failure',
        },
      };
    }

    // RSS URLì´ ìˆìœ¼ë©´ crawl_url ì—…ë°ì´íŠ¸
    if (newConfig.rssUrl) {
      updates.crawl_url = newConfig.rssUrl;
    }

    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const { error } = await (supabase as any)
      .from('crawl_sources')
      .update(updates)
      .eq('id', sourceId);

    if (error) {
      console.error('[AUTO-RECOVERY] Failed to update source config:', error);
    } else {
      console.log(`[AUTO-RECOVERY] âœ… Updated source config (ID: ${sourceId})`);
      console.log(`   ğŸ“Š New crawler_type: ${newConfig.crawlerType}`);
      console.log(`   ğŸ“Š Confidence: ${newConfig.confidence?.toFixed(2) || 'N/A'}`);
    }
  } catch (error) {
    console.error('[AUTO-RECOVERY] Error updating source config:', error);
  }
}

function validateCrawlResults(items: RawContentItem[]): ValidationResult {
  // 0ê±´ â†’ ì‹¤íŒ¨
  if (items.length === 0) {
    return { passed: false, reason: 'No items found' };
  }

  // í’ˆì§ˆ í†µê³„ ê³„ì‚°
  const qualityStats = getQualityStats(items);

  // ì“°ë ˆê¸° ë¹„ìœ¨ > 50% â†’ ì‹¤íŒ¨
  if (qualityStats.garbageRatio > 0.5) {
    return {
      passed: false,
      reason: `High garbage ratio: ${(qualityStats.garbageRatio * 100).toFixed(1)}%`,
      stats: {
        total: qualityStats.total,
        valid: qualityStats.valid,
        garbageRatio: qualityStats.garbageRatio,
        uniqueTitles: 0,
        uniqueUrls: 0,
      },
    };
  }

  // ìœ íš¨ ì•„ì´í…œ < 2ê±´ â†’ ì‹¤íŒ¨
  if (qualityStats.valid < 2) {
    return {
      passed: false,
      reason: `Insufficient valid items: ${qualityStats.valid}`,
      stats: {
        total: qualityStats.total,
        valid: qualityStats.valid,
        garbageRatio: qualityStats.garbageRatio,
        uniqueTitles: 0,
        uniqueUrls: 0,
      },
    };
  }

  // ì œëª© ë‹¤ì–‘ì„± ê²€ì‚¬
  const titles = items.map((item) => item.title.toLowerCase().trim());
  const uniqueTitles = new Set(titles).size;
  const titleDiversity = uniqueTitles / items.length;

  if (titleDiversity < 0.5) {
    return {
      passed: false,
      reason: `Low title diversity: ${(titleDiversity * 100).toFixed(1)}%`,
      stats: {
        total: qualityStats.total,
        valid: qualityStats.valid,
        garbageRatio: qualityStats.garbageRatio,
        uniqueTitles,
        uniqueUrls: 0,
      },
    };
  }

  // URL ë‹¤ì–‘ì„± ê²€ì‚¬
  const urls = items.map((item) => item.link.toLowerCase().trim());
  const uniqueUrls = new Set(urls).size;
  const urlDiversity = uniqueUrls / items.length;

  if (urlDiversity < 0.5) {
    return {
      passed: false,
      reason: `Low URL diversity: ${(urlDiversity * 100).toFixed(1)}%`,
      stats: {
        total: qualityStats.total,
        valid: qualityStats.valid,
        garbageRatio: qualityStats.garbageRatio,
        uniqueTitles,
        uniqueUrls,
      },
    };
  }

  // ëª¨ë“  ê²€ì¦ í†µê³¼
  return {
    passed: true,
    stats: {
      total: qualityStats.total,
      valid: qualityStats.valid,
      garbageRatio: qualityStats.garbageRatio,
      uniqueTitles,
      uniqueUrls,
    },
  };
}

/**
 * í¬ë¡¤ëŸ¬ íƒ€ì…ë³„ ê¸°ë³¸ í´ë°± ì²´ì¸
 * FIRECRAWL ì œê±° - ë²”ìš© ì „ëµë§Œ ì‚¬ìš© (í•˜ì´ë¸Œë¦¬ë“œ ìë™ ë³µêµ¬ê°€ ëŒ€ì²´)
 */
function getDefaultFallbacks(primaryType: CrawlerType): CrawlerType[] {
  switch (primaryType) {
    case 'RSS':
      return ['STATIC'];
    case 'SPA':
      return ['STATIC'];
    case 'STATIC':
      return [];
    case 'FIRECRAWL':
      return ['STATIC'];
    case 'API':
      return ['STATIC'];
    case 'PLATFORM_NAVER':
    case 'PLATFORM_KAKAO':
    case 'NEWSLETTER':
      return ['STATIC'];
    default:
      return ['STATIC'];
  }
}

/**
 * ì „ëµ íŒ¨í„´ ê¸°ë°˜ í¬ë¡¤ë§ ì‹¤í–‰ (í´ë°± ì²´ì¸ + í’ˆì§ˆ ê²€ì¦)
 */
async function crawlWithStrategy(source: CrawlSource): Promise<CrawledArticle[]> {
  const config = parseConfig(source);

  // 1. Primary ì „ëµ ê²°ì •
  const inferred = inferCrawlerType(source.base_url);
  const isLegacyType = source.crawler_type === 'static' || source.crawler_type === 'dynamic';
  const primaryType = isLegacyType
    ? inferred
    : ((source.crawler_type as CrawlerType) || inferred);

  // 2. Fallback ì²´ì¸ êµ¬ì„±
  const fallbacks = config._detection?.fallbackStrategies || getDefaultFallbacks(primaryType);
  const strategyChain = [primaryType, ...fallbacks].filter(
    (type, index, arr) => arr.indexOf(type) === index
  ); // ì¤‘ë³µ ì œê±°

  console.log(`\nğŸ“‹ [ì „ëµ ì²´ì¸] ${strategyChain.join(' â†’ ')}`);

  // 3. ì²´ì¸ ìˆœíšŒ (ê° ì „ëµ 30ì´ˆ íƒ€ì„ì•„ì›ƒ)
  for (let i = 0; i < strategyChain.length; i++) {
    const strategyType = strategyChain[i];
    const isFallback = i > 0;

    console.log(
      `\n${isFallback ? 'ğŸ”„ [ëŒ€ì²´ ì „ëµ]' : 'ğŸ¯ [ì£¼ ì „ëµ]'} ${strategyType} ì‹¤í–‰ ì¤‘... (${i + 1}/${strategyChain.length})`
    );

    try {
      // ì „ëµ ê°€ì ¸ì˜¤ê¸°
      console.log(`   âš™ï¸  ì „ëµ ë¡œë“œ ì¤‘...`);
      const strategy = getStrategy(strategyType);
      console.log(`   âœ… ì „ëµ ë¡œë“œ ì™„ë£Œ`);

      // íƒ€ì„ì•„ì›ƒ ì„¤ì • (30ì´ˆ)
      const timeoutPromise = new Promise<RawContentItem[]>((_, reject) =>
        setTimeout(() => reject(new Error('ì „ëµ íƒ€ì„ì•„ì›ƒ (30ì´ˆ)')), 30000)
      );

      const crawlPromise = strategy.crawlList(source);

      console.log(`   ğŸ” ì½˜í…ì¸  ëª©ë¡ í¬ë¡¤ë§ ì¤‘... (ìµœëŒ€ 30ì´ˆ)`);
      // ëª©ë¡ í¬ë¡¤ë§ (íƒ€ì„ì•„ì›ƒ ì ìš©)
      const rawItemsAll = await Promise.race([crawlPromise, timeoutPromise]);

      // ìµœì‹  5ê°œë§Œ ìœ ì§€ (ì‚¬ì´íŠ¸ ë‹¹ ì œí•œ)
      const rawItems = rawItemsAll.slice(0, 5);

      console.log(`   âœ… í¬ë¡¤ë§ ì™„ë£Œ: ${rawItemsAll.length}ê°œ ë°œê²¬ â†’ ìµœì‹  ${rawItems.length}ê°œ ì„ íƒ`);

      // 4. í’ˆì§ˆ ê²€ì¦
      console.log(`   ğŸ” í’ˆì§ˆ ê²€ì¦ ì¤‘...`);
      const validation = validateCrawlResults(rawItems);

      if (!validation.passed) {
        console.warn(
          `   âš ï¸  í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨: ${validation.reason}`
        );
        if (validation.stats) {
          console.warn(`   ğŸ“Š í†µê³„: ì „ì²´ ${validation.stats.total}ê°œ, ìœ íš¨ ${validation.stats.valid}ê°œ, ì“°ë ˆê¸° ë¹„ìœ¨ ${(validation.stats.garbageRatio * 100).toFixed(1)}%`);
        }

        // ë§ˆì§€ë§‰ ì „ëµì´ë©´ ìë™ ë³µêµ¬ ì‹œë„ (í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ)
        if (i === strategyChain.length - 1 && validation.stats && validation.stats.garbageRatio > 0.5) {
          console.log(`\nğŸ”„ [ìë™ ë³µêµ¬] í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨ - 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì¬ë¶„ì„ ì‹œë„...`);

          try {
            const { resolveStrategy } = await import('./strategy-resolver');
            const newStrategy = await resolveStrategy(source.base_url);

            // ìƒˆ ì „ëµì´ ë” ë†’ì€ ì‹ ë¢°ë„ë©´ ì ìš©
            if (newStrategy.confidence > 0.6) {
              console.log(`   âœ… ìƒˆ ì „ëµ ë°œê²¬: ${newStrategy.primaryStrategy} (confidence: ${(newStrategy.confidence * 100).toFixed(0)}%)`);
              console.log(`   ğŸ’¾ Config ì—…ë°ì´íŠ¸ ì¤‘...`);

              // Config ì—…ë°ì´íŠ¸
              await updateSourceConfig(source.id, {
                crawlerType: newStrategy.primaryStrategy,
                selectors: (newStrategy.selectors as unknown) as Record<string, unknown> | undefined,
                rssUrl: newStrategy.rssUrl || undefined,
                confidence: newStrategy.confidence,
                detectionMethod: newStrategy.detectionMethod,
              });

              // ìƒˆ ì „ëµìœ¼ë¡œ ì¬í¬ë¡¤ë§
              console.log(`   ğŸ”„ ìƒˆ ì „ëµìœ¼ë¡œ ì¬í¬ë¡¤ë§ ì‹œë„...`);
              const recoveryStrategy = getStrategy(newStrategy.primaryStrategy);

              const updatedSource: CrawlSource = {
                ...source,
                crawler_type: newStrategy.primaryStrategy,
                config: {
                  ...source.config,
                  selectors: newStrategy.selectors || source.config?.selectors,
                  _detection: {
                    method: newStrategy.detectionMethod,
                    confidence: newStrategy.confidence,
                    timestamp: new Date().toISOString(),
                  },
                },
                ...(newStrategy.rssUrl && { crawl_url: newStrategy.rssUrl }),
              };

              const recoveryItems = await recoveryStrategy.crawlList(updatedSource);
              const recoveryValidation = validateCrawlResults(recoveryItems.slice(0, 5));

              if (recoveryValidation.passed) {
                console.log(`   âœ… ìë™ ë³µêµ¬ ì„±ê³µ! (${recoveryItems.length}ê°œ ë°œê²¬)`);

                // ë³¸ë¬¸ í¬ë¡¤ë§ (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼)
                const articles: CrawledArticle[] = [];
                for (let idx = 0; idx < Math.min(recoveryItems.length, 5); idx++) {
                  const item = recoveryItems[idx];
                  if (!item.content && recoveryStrategy.crawlContent) {
                    try {
                      const result = await recoveryStrategy.crawlContent(item.link, config.content_selectors);
                      if (typeof result === 'string') {
                        item.content = result;
                      } else {
                        item.content = result.content;
                        if (!item.thumbnail && result.thumbnail) {
                          item.thumbnail = result.thumbnail;
                        }
                      }
                    } catch (error) {
                      console.error(`   âŒ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: ${item.link}`, error instanceof Error ? error.message : error);
                    }
                    await new Promise((resolve) => setTimeout(resolve, config.crawl_config?.delay || 500));
                  }
                  articles.push(convertToArticle(item, source, config.category));
                }

                const filtered = filterGarbageArticles(articles, source.name);
                console.log(`   âœ… ìë™ ë³µêµ¬ ìµœì¢… ê²°ê³¼: ${filtered.length}ê°œ ì•„í‹°í´`);
                return filtered;
              } else {
                console.warn(`   âš ï¸  ìë™ ë³µêµ¬ ì‹¤íŒ¨: ìƒˆ ì „ëµë„ í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨`);
              }
            } else {
              console.warn(`   âš ï¸  ìë™ ë³µêµ¬ ì‹¤íŒ¨: ë‚®ì€ ì‹ ë¢°ë„ (${(newStrategy.confidence * 100).toFixed(0)}%)`);
            }
          } catch (error) {
            console.error(`   âŒ ìë™ ë³µêµ¬ ì˜¤ë¥˜:`, error instanceof Error ? error.message : error);
          }
        }

        // ìë™ ë³µêµ¬ ì‹¤íŒ¨ ë˜ëŠ” ë§ˆì§€ë§‰ ì „ëµì´ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜
        if (i === strategyChain.length - 1) {
          console.error(`   âŒ ëª¨ë“  ì „ëµ ì‹¤íŒ¨ - "${source.name}" í¬ë¡¤ë§ ì¤‘ë‹¨`);
          return [];
        }

        console.log(`   ğŸ”„ ë‹¤ìŒ ì „ëµ ì‹œë„ ì¤‘...`);
        // ë‹¤ìŒ ì „ëµ ì‹œë„
        continue;
      }

      console.log(`   âœ… í’ˆì§ˆ ê²€ì¦ í†µê³¼`);
      if (validation.stats) {
        console.log(`   ğŸ“Š í†µê³„: ì „ì²´ ${validation.stats.total}ê°œ, ìœ íš¨ ${validation.stats.valid}ê°œ, ì¤‘ë³µì œê±° ${validation.stats.uniqueTitles}ê°œ`);
      }

      // 5. ë³¸ë¬¸ í¬ë¡¤ë§
      console.log(`\n   ğŸ“„ ë³¸ë¬¸ ì¶”ì¶œ ì‹œì‘... (${rawItems.length}ê°œ)`);
      const articles: CrawledArticle[] = [];
      let contentFetchCount = 0;

      for (let idx = 0; idx < rawItems.length; idx++) {
        const item = rawItems[idx];
        if (!item.content && strategy.crawlContent) {
          try {
            console.log(`      [${idx + 1}/${rawItems.length}] "${item.title.substring(0, 40)}..." ë³¸ë¬¸ ì¶”ì¶œ ì¤‘...`);
            const result = await strategy.crawlContent(item.link, config.content_selectors);

            if (typeof result === 'string') {
              item.content = result;
            } else {
              item.content = result.content;
              if (!item.thumbnail && result.thumbnail) {
                item.thumbnail = result.thumbnail;
              }
            }
            contentFetchCount++;
            console.log(`      âœ… ë³¸ë¬¸ ì¶”ì¶œ ì™„ë£Œ (${item.content.length}ì)`);
          } catch (error) {
            console.error(`      âŒ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: ${item.link}`, error instanceof Error ? error.message : error);
          }

          await new Promise((resolve) => setTimeout(resolve, config.crawl_config?.delay || 500));
        }

        articles.push(convertToArticle(item, source, config.category));
      }

      console.log(`   âœ… ë³¸ë¬¸ ì¶”ì¶œ ì™„ë£Œ: ${contentFetchCount}/${rawItems.length}ê°œ ì„±ê³µ`);

      // 6. ì“°ë ˆê¸° í•„í„° ì ìš©
      console.log(`   ğŸ—‘ï¸  í’ˆì§ˆ í•„í„°ë§ ì¤‘...`);
      const filtered = filterGarbageArticles(articles, source.name);
      const filteredCount = articles.length - filtered.length;
      if (filteredCount > 0) {
        console.log(`   ğŸ—‘ï¸  í•„í„°ë§ ì œê±°: ${filteredCount}ê°œ`);
      }

      console.log(`\n   âœ… ${strategyType} ì „ëµ ì„±ê³µ: ìµœì¢… ${filtered.length}ê°œ ì•„í‹°í´`);
      return filtered;
    } catch (error) {
      console.error(`   âŒ ${strategyType} ì „ëµ ì˜¤ë¥˜:`, error instanceof Error ? error.message : error);

      // ë§ˆì§€ë§‰ ì „ëµì´ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜
      if (i === strategyChain.length - 1) {
        console.error(`   âŒ ëª¨ë“  ì „ëµ ì†Œì§„ - "${source.name}" í¬ë¡¤ë§ ì‹¤íŒ¨`);
        return [];
      }

      console.log(`   ğŸ”„ ë‹¤ìŒ ì „ëµ ì‹œë„ ì¤‘...`);
      // ë‹¤ìŒ ì „ëµ ì‹œë„
      continue;
    }
  }

  // ëª¨ë“  ì „ëµ ì‹¤íŒ¨
  console.error(`âŒ í¬ë¡¤ë§ ì‹¤íŒ¨ - "${source.name}": ëª¨ë“  ì „ëµ ì‹¤íŒ¨`);
  return [];
}

/**
 * í¬ë¡¤ëŸ¬ ì„ íƒ (ì „ëµ íŒ¨í„´ ìš°ì„ , ë ˆê±°ì‹œ í´ë°±)
 */
function getCrawler(source: CrawlSource): (source: CrawlSource) => Promise<CrawledArticle[]> {
  // 1. URL ê¸°ë°˜ìœ¼ë¡œ ìµœì  ì „ëµ ì¶”ë¡ 
  const inferred = inferCrawlerType(source.base_url);
  console.log(`ğŸ” ìë™ ê°ì§€ëœ ì „ëµ: ${inferred} (URL ê¸°ë°˜)`);

  // 2. ìƒˆ ì „ëµ íŒ¨í„´ ì‚¬ìš© (ì¶”ë¡ ëœ íƒ€ì… or crawler_typeì´ ìœ íš¨í•œ ê²½ìš°)
  if (isValidCrawlerType(inferred)) {
    console.log(`âœ… ì „ëµ íŒ¨í„´ ì‚¬ìš©: ${inferred}`);
    return crawlWithStrategy;
  }

  // 3. crawler_typeì´ ëª…ì‹œì ìœ¼ë¡œ ìœ íš¨í•œ ê²½ìš°
  if (source.crawler_type && isValidCrawlerType(source.crawler_type)) {
    console.log(`âœ… ì „ëµ íŒ¨í„´ ì‚¬ìš©: ${source.crawler_type} (ì„¤ì •ë¨)`);
    return crawlWithStrategy;
  }

  // 4. ë ˆê±°ì‹œ í´ë°± (ì‚¬ì´íŠ¸ë³„ í¬ë¡¤ëŸ¬)
  if (LEGACY_CRAWLER_REGISTRY[source.name]) {
    console.log(`ğŸ”„ ë ˆê±°ì‹œ í¬ë¡¤ëŸ¬ ì‚¬ìš©: ${source.name}`);
    return LEGACY_CRAWLER_REGISTRY[source.name];
  }

  // 5. ê¸°ë³¸ê°’: ì „ëµ íŒ¨í„´
  console.log(`âœ… ê¸°ë³¸ ì „ëµ íŒ¨í„´ ì‚¬ìš©`);
  return crawlWithStrategy;
}

/**
 * ì•„í‹°í´ ì €ì¥
 */
export async function saveArticles(
  articles: CrawledArticle[],
  supabase: SupabaseClient<Database>
): Promise<{ saved: number; skipped: number }> {
  let saved = 0;
  let skipped = 0;

  for (let idx = 0; idx < articles.length; idx++) {
    const article = articles[idx];
    try {
      // source_id ê¸°ì¤€ ì¤‘ë³µ í™•ì¸
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const { data: existing } = await (supabase as any)
        .from('articles')
        .select('id')
        .eq('source_id', article.source_id)
        .single();

      if (existing) {
        skipped++;
        console.log(`   â­ï¸  [${idx + 1}/${articles.length}] ê±´ë„ˆëœ€ (ì¤‘ë³µ): "${article.title.substring(0, 40)}..."`);
        continue;
      }

      // ìƒˆ ì•„í‹°í´ ì €ì¥
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const { error } = await (supabase as any).from('articles').insert({
        source_id: article.source_id,
        source_name: article.source_name,
        source_url: article.source_url,
        title: article.title,
        thumbnail_url: article.thumbnail_url,
        content_preview: article.content_preview,
        summary: article.summary,
        author: article.author,
        published_at: article.published_at,
        category: article.category,
      });

      if (error) {
        console.error(`   âŒ [${idx + 1}/${articles.length}] ì €ì¥ ì‹¤íŒ¨: ${article.title}`, error);
      } else {
        saved++;
        console.log(`   âœ… [${idx + 1}/${articles.length}] ì €ì¥ ì™„ë£Œ: "${article.title.substring(0, 40)}..."`);
      }
    } catch (error) {
      console.error(`   âŒ [${idx + 1}/${articles.length}] ì˜¤ë¥˜:`, error);
    }
  }

  return { saved, skipped };
}

/**
 * ë‹¨ì¼ ì†ŒìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰
 */
export async function runCrawler(
  source: CrawlSource,
  supabase: SupabaseClient<Database>,
  options?: { dryRun?: boolean; verbose?: boolean }
): Promise<CrawlResult> {
  const result: CrawlResult = {
    found: 0,
    new: 0,
    errors: [],
  };

  const startTime = Date.now();

  // crawl_urlì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš© (URL ìµœì í™” ê²°ê³¼)
  const effectiveUrl = source.crawl_url || source.base_url;
  const effectiveSource: CrawlSource = {
    ...source,
    base_url: effectiveUrl, // í¬ë¡¤ë§ ì‹œ ìµœì í™”ëœ URL ì‚¬ìš©
  };

  try {
    console.log(`\n${'â”€'.repeat(80)}`);
    console.log(`ğŸ¯ í¬ë¡¤ë§ ëŒ€ìƒ: ${source.name}`);
    if (source.crawl_url && source.crawl_url !== source.base_url) {
      console.log(`   ğŸ“ ì›ë³¸ URL: ${source.base_url}`);
      console.log(`   âœ¨ í¬ë¡¤ë§ URL: ${source.crawl_url}`);
    } else {
      console.log(`   ğŸ“ URL: ${source.base_url}`);
    }
    console.log(`   ğŸ”§ íƒ€ì…: ${source.crawler_type || 'ìë™ê°ì§€'}`);
    console.log(`   â° ì‹œì‘: ${new Date().toLocaleString('ko-KR', { timeZone: 'Asia/Seoul' })}`);
    if (options?.dryRun) console.log(`   ğŸ§ª ëª¨ë“œ: í…ŒìŠ¤íŠ¸ (DB ì €ì¥ ì•ˆí•¨)`);
    console.log(`${'â”€'.repeat(80)}`);

    // í¬ë¡¤ëŸ¬ ì„ íƒ ë° ì‹¤í–‰
    const crawler = getCrawler(effectiveSource);
    console.log(`\nğŸ¤– í¬ë¡¤ëŸ¬: ${crawler.name || 'ì „ëµ ê¸°ë°˜'}`);

    // í¬ë¡¤ë§ ì‹¤í–‰
    console.log(`ğŸ” ì•„í‹°í´ ìˆ˜ì§‘ ì¤‘...`);
    const articlesAll = await crawler(effectiveSource);

    // ìµœì‹  5ê°œë§Œ ìœ ì§€ (ì‚¬ì´íŠ¸ ë‹¹ ì œí•œ)
    const articles = articlesAll.slice(0, 5);

    result.found = articles.length;
    console.log(`\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼: ${articlesAll.length}ê°œ ë°œê²¬ â†’ ìµœì‹  ${articles.length}ê°œ ì„ íƒ`);

    if (articles.length === 0) {
      console.log(`âš ï¸  ì•„í‹°í´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - ${source.name}`);
      return result;
    }

    // ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° ê°€ì ¸ì˜¤ê¸° (ë ˆê±°ì‹œ í¬ë¡¤ëŸ¬ìš©)
    console.log(`\nğŸ“„ ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° ì¶”ì¶œ ì¤‘...`);
    let previewCount = 0;
    for (let idx = 0; idx < articles.length; idx++) {
      const article = articles[idx];
      if (!article.content_preview) {
        try {
          console.log(`   [${idx + 1}/${articles.length}] "${article.title.substring(0, 40)}..." ì¶”ì¶œ ì¤‘...`);
          const content = await fetchArticleContent(article.source_url);
          if (content) {
            article.content_preview = content.substring(0, 3000);
            previewCount++;
            console.log(`   âœ… ì¶”ì¶œ ì™„ë£Œ (${content.length}ì)`);
          }
        } catch (error) {
          if (options?.verbose) {
            console.error(`   âŒ ì¶”ì¶œ ì‹¤íŒ¨: ${article.title}`, error);
          }
        }
        await new Promise((resolve) => setTimeout(resolve, 500));
      }
    }
    if (previewCount > 0) {
      console.log(`âœ… ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° ì¶”ì¶œ ì™„ë£Œ: ${previewCount}ê°œ`);
    }

    // DB ì €ì¥ (dry-runì´ ì•„ë‹Œ ê²½ìš°)
    if (!options?.dryRun) {
      console.log(`\nğŸ’¾ DB ì €ì¥ ì¤‘... (${articles.length}ê°œ)`);
      const { saved, skipped } = await saveArticles(articles, supabase);
      result.new = saved;

      const duration = ((Date.now() - startTime) / 1000).toFixed(2);
      console.log(`\n${'='.repeat(80)}`);
      console.log(`âœ… í¬ë¡¤ë§ ì™„ë£Œ: ${source.name}`);
      console.log(`${'='.repeat(80)}`);
      console.log(`â±ï¸  ì†Œìš”ì‹œê°„: ${duration}ì´ˆ`);
      console.log(`ğŸ“Š ë°œê²¬: ${result.found}ê°œ`);
      console.log(`ğŸ’¾ ì €ì¥: ${result.new}ê°œ`);
      console.log(`â­ï¸  ê±´ë„ˆëœ€: ${skipped}ê°œ (ì¤‘ë³µ)`);
      console.log(`${'='.repeat(80)}\n`);
    } else {
      const duration = ((Date.now() - startTime) / 1000).toFixed(2);
      console.log(`\n${'='.repeat(80)}`);
      console.log(`ğŸ§ª í…ŒìŠ¤íŠ¸ ì™„ë£Œ: ${source.name}`);
      console.log(`${'='.repeat(80)}`);
      console.log(`â±ï¸  ì†Œìš”ì‹œê°„: ${duration}ì´ˆ`);
      console.log(`ğŸ“Š ì €ì¥ ì˜ˆì •: ${result.found}ê°œ`);
      if (options?.verbose) {
        console.log('\nğŸ“° ì•„í‹°í´ ëª©ë¡:');
        articles.forEach((a, i) => {
          console.log(`  ${i + 1}. ${a.title}`);
          console.log(`     ğŸ”— URL: ${a.source_url}`);
          console.log(`     ğŸ“… ë‚ ì§œ: ${a.published_at || 'N/A'}`);
        });
      }
      console.log(`${'='.repeat(80)}\n`);
    }
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    result.errors.push(errorMessage);
    console.error(`[CRAWL ERROR] ${source.name}:`, error);
    if (options?.verbose && error instanceof Error) {
      console.error(`[CRAWL ERROR] Stack:`, error.stack);
    }
  }

  return result;
}

/**
 * ëª¨ë“  í™œì„± ì†ŒìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰
 */
export async function runAllCrawlers(
  supabase: SupabaseClient<Database>,
  options?: { dryRun?: boolean; verbose?: boolean }
): Promise<{ source: string; result: CrawlResult }[]> {
  const results: { source: string; result: CrawlResult }[] = [];

  try {
    // í™œì„± ì†ŒìŠ¤ ëª©ë¡ ì¡°íšŒ
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const { data: sourcesData, error } = await (supabase as any)
      .from('crawl_sources')
      .select('*')
      .eq('is_active', true)
      .order('priority', { ascending: false });

    if (error || !sourcesData) {
      console.error('[CRAWL] Failed to fetch crawl sources:', error);
      return results;
    }

    const sources = sourcesData as CrawlSource[];
    console.log(`[CRAWL] Found ${sources.length} active sources\n`);

    for (const source of sources) {
      const result = await runCrawler(source, supabase, options);
      results.push({ source: source.name, result });

      // last_crawled_at ì—…ë°ì´íŠ¸ (dry-runì´ ì•„ë‹Œ ê²½ìš°)
      if (!options?.dryRun) {
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        await (supabase as any)
          .from('crawl_sources')
          .update({ last_crawled_at: new Date().toISOString() })
          .eq('id', source.id);
      }

      // ì†ŒìŠ¤ ê°„ ë”œë ˆì´
      await new Promise((resolve) => setTimeout(resolve, 2000));
    }

    // ë¸Œë¼ìš°ì € ì •ë¦¬ (SPA í¬ë¡¤ëŸ¬ ì‚¬ìš© ì‹œ)
    await closeBrowser();
  } catch (error) {
    console.error('[CRAWL] Fatal error:', error);
    await closeBrowser();
  }

  // ê²°ê³¼ ìš”ì•½
  console.log(`\n${'='.repeat(60)}`);
  console.log('[CRAWL SUMMARY]');
  console.log(`${'='.repeat(60)}`);

  let totalFound = 0;
  let totalNew = 0;
  let totalErrors = 0;

  for (const { source, result } of results) {
    totalFound += result.found;
    totalNew += result.new;
    totalErrors += result.errors.length;
    const status = result.errors.length > 0 ? 'âŒ' : result.new > 0 ? 'âœ…' : 'âšª';
    console.log(`${status} ${source}: ${result.found} found, ${result.new} new`);
  }

  console.log(`${'='.repeat(60)}`);
  console.log(`Total: ${totalFound} found, ${totalNew} new, ${totalErrors} errors`);
  console.log(`${'='.repeat(60)}\n`);

  return results;
}

/**
 * íŠ¹ì • ì†ŒìŠ¤ IDë¡œ í¬ë¡¤ë§ ì‹¤í–‰
 */
export async function runCrawlerById(
  sourceId: string,
  supabase: SupabaseClient<Database>,
  options?: { dryRun?: boolean; verbose?: boolean }
): Promise<CrawlResult | null> {
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  const { data: source, error } = await (supabase as any)
    .from('crawl_sources')
    .select('*')
    .eq('id', sourceId)
    .single();

  if (error || !source) {
    console.error(`[CRAWL] Source not found: ${sourceId}`);
    return null;
  }

  return runCrawler(source as CrawlSource, supabase, options);
}

// Export types
export type { CrawlerType, CrawlResult, CrawledArticle, RawContentItem };

// Export strategies
export { getStrategy, inferCrawlerType, isValidCrawlerType, closeBrowser };

// Export legacy crawlers for backward compatibility
export {
  crawlIconsumer,
  crawlBrunch,
  crawlWiseapp,
  crawlOpenads,
  crawlRetailtalk,
  crawlStonebc,
  crawlBuybrand,
  crawlWithCheerio,
  crawlWithPlaywright,
  fetchArticleContent,
};
