import { NextRequest, NextResponse } from 'next/server';
import { revalidatePath } from 'next/cache';
import { createServiceClient } from '@/lib/supabase/server';
import { resolveStrategy } from '@/lib/crawlers/strategy-resolver';
import { verifySameOrigin, verifyCronAuth } from '@/lib/auth';
import { getCache, setCache, invalidateCache, CACHE_KEYS, CACHE_TTL } from '@/lib/cache';

// GET /api/sources - Get all crawl sources (In-Memory cached)
export async function GET() {
  try {
    // Layer 1: In-Memory cache
    const cached = getCache<{ sources: unknown[] }>(CACHE_KEYS.SOURCES);
    if (cached) {
      return NextResponse.json(cached, {
        headers: {
          'Cache-Control': 'private, max-age=30, stale-while-revalidate=60',
          'X-Cache': 'HIT',
        },
      });
    }

    const supabase = createServiceClient();

    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const { data, error } = await (supabase as any)
      .from('crawl_sources')
      .select('*')
      .order('priority', { ascending: false });

    if (error) {
      console.error('Error fetching sources:', error);
      return NextResponse.json({ error: error.message }, { status: 500 });
    }

    const body = { sources: data || [] };
    setCache(CACHE_KEYS.SOURCES, body, CACHE_TTL.SOURCES);

    return NextResponse.json(body, {
      headers: {
        'Cache-Control': 'private, max-age=30, stale-while-revalidate=60',
        'X-Cache': 'MISS',
      },
    });
  } catch (error) {
    const message = error instanceof Error ? error.message : 'Unknown error';
    const stack = error instanceof Error ? error.stack : undefined;
    console.error('[GET /api/sources] Error:', message, stack);
    return NextResponse.json(
      { error: message, detail: stack?.split('\n').slice(0, 3).join(' | ') },
      { status: 500 }
    );
  }
}

// POST /api/sources - Add new crawl sources (requires auth)
export async function POST(request: NextRequest) {
  try {
    // Require same-origin (browser) or cron auth (server)
    if (!verifySameOrigin(request) && !verifyCronAuth(request)) {
      return NextResponse.json(
        { error: 'Unauthorized' },
        { status: 401 }
      );
    }

    const supabase = createServiceClient();
    const body = await request.json();
    const { sources, deleteIds } = body;

    if (!sources || !Array.isArray(sources)) {
      return NextResponse.json(
        { error: 'Invalid sources data' },
        { status: 400 }
      );
    }

    // ì‚­ì œ ìš”ì²­ëœ ì†ŒìŠ¤ ì²˜ë¦¬
    if (deleteIds && Array.isArray(deleteIds) && deleteIds.length > 0) {
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const { error: deleteError } = await (supabase as any)
        .from('crawl_sources')
        .delete()
        .in('id', deleteIds);

      if (deleteError) {
        console.error('Error deleting sources:', deleteError);
      } else {
        console.log(`[SOURCES] Deleted ${deleteIds.length} sources: ${deleteIds.join(', ')}`);
      }
    }

    const results = [];
    const analysisResults: {
      url: string;
      method: string;
      confidence: number;
      crawlerType: string;
      spaDetected: boolean;
      rssUrl?: string;
    }[] = [];

    // ëª¨ë“  URLì— ëŒ€í•´ í†µí•© ì „ëµ í•´ì„ ì‹¤í–‰
    const resolutionMap = new Map<
      string,
      Awaited<ReturnType<typeof resolveStrategy>>
    >();
    const allUrls = sources
      .filter((s: { url?: string }) => s.url)
      .map((s: { url: string }) => s.url);

    if (allUrls.length > 0) {
      console.log(`\n[POST /api/sources] ğŸš€ ${allUrls.length}ê°œ ì†ŒìŠ¤ ë¶„ì„ ì‹œì‘...`);

      const resolutions = await Promise.allSettled(
        allUrls.map((url: string, index: number) => {
          console.log(`[POST /api/sources] ğŸ“ [${index + 1}/${allUrls.length}] ë¶„ì„ ì¤‘: ${url}`);
          return resolveStrategy(url);
        })
      );

      allUrls.forEach((url: string, i: number) => {
        const result = resolutions[i];
        if (result.status === 'fulfilled') {
          resolutionMap.set(url, result.value);
          console.log(
            `[POST /api/sources] âœ… [${i + 1}/${allUrls.length}] ì™„ë£Œ: ${result.value.primaryStrategy} (${result.value.detectionMethod})`
          );
        } else {
          console.error(
            `[POST /api/sources] âŒ [${i + 1}/${allUrls.length}] ì‹¤íŒ¨: ${url}`,
            result.reason
          );
        }
      });

      console.log(`[POST /api/sources] ğŸ‰ ${allUrls.length}ê°œ ì†ŒìŠ¤ ë¶„ì„ ì™„ë£Œ\n`);
    }

    for (const source of sources) {
      const { url, name, category, crawlerType: userCrawlerType } = source;

      if (!url) continue;

      const resolution = resolutionMap.get(url);

      // Check if source already exists
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const { data: existing } = await (supabase as any)
        .from('crawl_sources')
        .select('id, config, crawler_type')
        .eq('base_url', url)
        .single();

      if (existing) {
        // Update existing source â€” selectorsê°€ ì—†ìœ¼ë©´ í•´ì„ ê²°ê³¼ ì ìš©
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const existingConfig = (existing.config as Record<string, unknown>) || {};
        const hasSelectors =
          existingConfig.selectors && typeof existingConfig.selectors === 'object';

        const updatedConfig = {
          ...existingConfig,
          category,
          // selectorsê°€ ì—†ê³  í•´ì„ ì„±ê³µ ì‹œ ì ìš©
          ...(!hasSelectors && resolution?.selectors && { selectors: resolution.selectors }),
          ...(!hasSelectors &&
            resolution?.pagination && { pagination: resolution.pagination }),
          ...(resolution?.rssUrl && {
            crawl_config: { rssUrl: resolution.rssUrl },
          }),
          // ì „ëµ í•´ì„ ë©”íƒ€ë°ì´í„° ì¶”ê°€
          ...(resolution && {
            _detection: {
              method: resolution.detectionMethod,
              confidence: resolution.confidence,
              fallbackStrategies: resolution.fallbackStrategies,
            },
          }),
        };

        // ì‚¬ìš©ìê°€ ì„ íƒí•œ crawlerType ìš°ì„  (ë‹¨, 'AUTO'ë©´ ë¬´ì‹œí•˜ê³  ìë™ í•´ì„ ì‚¬ìš©)
        const crawlerTypeUpdate = userCrawlerType && userCrawlerType !== 'AUTO'
          ? { crawler_type: userCrawlerType }
          : resolution
          ? { crawler_type: resolution.primaryStrategy }
          : {};

        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const { data, error } = await (supabase as any)
          .from('crawl_sources')
          .update({
            name: name || extractDomainName(url),
            config: updatedConfig,
            ...crawlerTypeUpdate,
          })
          .eq('id', existing.id)
          .select()
          .single();

        if (!error && data) {
          results.push(data);
        }

        if (resolution) {
          analysisResults.push({
            url,
            method: resolution.detectionMethod,
            confidence: resolution.confidence,
            crawlerType: resolution.primaryStrategy,
            spaDetected: resolution.spaDetected,
            ...(resolution.rssUrl && { rssUrl: resolution.rssUrl }),
          });
        }
      } else {
        // Insert new source with resolved strategy
        console.log(`\nğŸ” [SOURCES DEBUG] URL: ${url}`);
        console.log(`ğŸ” [SOURCES DEBUG] resolution ì¡´ì¬? ${!!resolution}`);
        console.log(`ğŸ” [SOURCES DEBUG] resolution?.primaryStrategy: ${resolution?.primaryStrategy}`);
        console.log(`ğŸ” [SOURCES DEBUG] resolution?.detectionMethod: ${resolution?.detectionMethod}`);
        console.log(`ğŸ” [SOURCES DEBUG] resolution?.confidence: ${resolution?.confidence}`);
        console.log(`ğŸ” [SOURCES DEBUG] userCrawlerType: ${userCrawlerType}`);

        // ì‚¬ìš©ìê°€ ì„ íƒí•œ crawlerType ìš°ì„  (ë‹¨, 'AUTO'ë©´ ë¬´ì‹œ), ì—†ìœ¼ë©´ í•´ì„ ê²°ê³¼, ê·¸ê²ƒë„ ì—†ìœ¼ë©´ SPA
        const crawlerType = (userCrawlerType && userCrawlerType !== 'AUTO' ? userCrawlerType : null)
          || resolution?.primaryStrategy
          || 'SPA';

        console.log(
          `[SOURCES] New source: ${url} -> crawler_type: ${crawlerType} (user: ${userCrawlerType || 'none'}, method: ${resolution?.detectionMethod || 'none'}, confidence: ${resolution?.confidence || 0})`
        );

        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const { data, error } = await (supabase as any)
          .from('crawl_sources')
          .insert({
            name: name || extractDomainName(url),
            base_url: url,
            crawler_type: crawlerType,
            config: {
              category,
              ...(resolution?.selectors && { selectors: resolution.selectors }),
              ...(resolution?.pagination && { pagination: resolution.pagination }),
              ...(resolution?.rssUrl && {
                crawl_config: { rssUrl: resolution.rssUrl },
              }),
              // ì „ëµ í•´ì„ ë©”íƒ€ë°ì´í„°
              ...(resolution && {
                _detection: {
                  method: resolution.detectionMethod,
                  confidence: resolution.confidence,
                  fallbackStrategies: resolution.fallbackStrategies,
                },
              }),
            },
            is_active: true,
            priority: 1,
          })
          .select()
          .single();

        if (!error && data) {
          results.push(data);
        }

        if (resolution) {
          analysisResults.push({
            url,
            method: resolution.detectionMethod,
            confidence: resolution.confidence,
            crawlerType,
            spaDetected: resolution.spaDetected,
            ...(resolution.rssUrl && { rssUrl: resolution.rssUrl }),
          });
        }
      }
    }

    // ë³€ê²½ í›„ ìºì‹œ ë¬´íš¨í™”
    invalidateCache(CACHE_KEYS.SOURCES);

    // Next.js ìºì‹œ ë¬´íš¨í™” (Server Component í˜ì´ì§€ ì¬ë Œë”ë§)
    revalidatePath('/sources/add');

    // ìš”ì•½ ë¡œê·¸
    console.log(`\n${'='.repeat(60)}`);
    console.log(`[POST /api/sources] ğŸ“Š ì†ŒìŠ¤ ì €ì¥ ì™„ë£Œ ìš”ì•½`);
    console.log(`${'='.repeat(60)}`);
    console.log(`ì´ ì†ŒìŠ¤: ${results.length}ê°œ`);

    if (analysisResults.length > 0) {
      console.log(`\në¶„ì„ ê²°ê³¼:`);
      const methodCount: Record<string, number> = {};
      const typeCount: Record<string, number> = {};

      analysisResults.forEach((result) => {
        methodCount[result.method] = (methodCount[result.method] || 0) + 1;
        typeCount[result.crawlerType] = (typeCount[result.crawlerType] || 0) + 1;
      });

      console.log(`ê°ì§€ ë°©ë²•ë³„:`);
      Object.entries(methodCount).forEach(([method, count]) => {
        console.log(`  - ${method}: ${count}ê°œ`);
      });

      console.log(`\ní¬ë¡¤ëŸ¬ íƒ€ì…ë³„:`);
      Object.entries(typeCount).forEach(([type, count]) => {
        console.log(`  - ${type}: ${count}ê°œ`);
      });

      const avgConfidence =
        analysisResults.reduce((sum, r) => sum + r.confidence, 0) / analysisResults.length;
      console.log(`\ní‰ê·  ì‹ ë¢°ë„: ${(avgConfidence * 100).toFixed(1)}%`);
    }

    console.log(`${'='.repeat(60)}\n`);

    return NextResponse.json({
      success: true,
      sources: results,
      analysis: analysisResults,
    });
  } catch (error) {
    const message = error instanceof Error ? error.message : 'Unknown error';
    const stack = error instanceof Error ? error.stack : undefined;
    console.error('[POST /api/sources] Error:', message, stack);
    return NextResponse.json(
      { error: message, detail: stack?.split('\n').slice(0, 3).join(' | ') },
      { status: 500 }
    );
  }
}

function extractDomainName(url: string): string {
  try {
    const domain = new URL(url).hostname.replace('www.', '');
    const parts = domain.split('.');
    return parts[0].charAt(0).toUpperCase() + parts[0].slice(1);
  } catch {
    return url;
  }
}
